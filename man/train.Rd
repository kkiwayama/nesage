% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/util.R
\name{train}
\alias{train}
\title{Train the Negative-binomial Sparse Additive Generative model.}
\usage{
train(iter, cnt, library.size = NULL, mean.cnt, topic.n,
  alpha.init = 0.1, update.alpha = FALSE, sgm.init = 0.01,
  dispersion.init = 1, rho = 0.95, eps = 1e-06, batch.size = NULL,
  model = NULL)
}
\arguments{
\item{iter}{Number of iterations for training the model.}

\item{cnt}{A matrix of read counts. Each row and column correspond to a gene and sample, respectively.}

\item{library.size}{A vector of library sizes (i.e. total read count) of samples. If Null is given, 
colSums(cnt) is automatically assigned. Default NULL.}

\item{mean.cnt}{A vector of log transformed values of expected read count for genes. 
log(rowSums(cnt) / sum(cnt)) is recommended.}

\item{topic.n}{Number of topics.}

\item{alpha.init}{Initial value of the parameters of the prior Dirichlet distribution for topic distributions. 
Default 0.1.}

\item{update.alpha}{Boolean value. If True, the parameters of the prior Dirichlet distribution is updated. 
Default FALSE}

\item{sgm.init}{Initial standard deviation of the posterior distribution of eta. Default 0.01.}

\item{dispersion.init}{Initial value of a dispersion parameter. Default 1.}

\item{rho}{Parameter for AdaDelta. Default 0.95}

\item{eps}{Parameter for AdaDelta. Default 1e-6}

\item{batch.size}{Minibatch size for stochastic gradient descent. If Null, number of columns of cnt is 
automatically assigned. Default NULL.}

\item{model}{If a list returned by this function rather than NULL is given, training restarts. Default NULL.}
}
\value{
A list containing the parameters of the trained model.
}
\description{
Train the Negative-binomial Sparse Additive Generative model.
}
\examples{
\dontrun{
# Training without updating alpha. 
model <- nesage::train(
    iter = 1000, 
    cnt = cnt, 
    mean.cnt = log(rowSums(cnt)/sum(cnt)), 
    topic.n = 10, 
    update.alpha = FALSE
)
# Restart training and update alpha. 
model <- nesage::train(
    iter = 1000, 
    cnt = cnt, 
    model = model, 
    update.alpha = TRUE
)
}

}
